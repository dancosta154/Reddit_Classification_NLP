{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81be881-0745-4d4c-b4ab-137b7546619d",
   "metadata": {},
   "source": [
    "## Notebook Description\n",
    "This notebook is dedicated to scraping posts from Reddit, for the Backpacking and Ultrarunning subreddits, then saving the output .csv in the `raw_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63230c76-a0a5-4839-867b-c85bc9e42632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07144c18-335a-41d1-98de-9d8c70f8bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 100 posts for the backpacking subreddit\n",
      "Scraped 200 posts for the backpacking subreddit\n",
      "Scraped 300 posts for the backpacking subreddit\n",
      "Scraped 400 posts for the backpacking subreddit\n",
      "Scraped 500 posts for the backpacking subreddit\n",
      "Scraped 600 posts for the backpacking subreddit\n",
      "Scraped 700 posts for the backpacking subreddit\n",
      "Scraped 800 posts for the backpacking subreddit\n",
      "Scraped 900 posts for the backpacking subreddit\n",
      "Scraped 1000 posts for the backpacking subreddit\n",
      "Scraped 1100 posts for the backpacking subreddit\n",
      "Scraped 1200 posts for the backpacking subreddit\n",
      "Scraped 1300 posts for the backpacking subreddit\n",
      "Scraped 1400 posts for the backpacking subreddit\n",
      "Scraped 1500 posts for the backpacking subreddit\n",
      "Scraped 1600 posts for the backpacking subreddit\n",
      "Scraped 1700 posts for the backpacking subreddit\n",
      "Scraped 1800 posts for the backpacking subreddit\n",
      "Scraped 1900 posts for the backpacking subreddit\n",
      "Scraped 2000 posts for the backpacking subreddit\n",
      "Scraped 100 posts for the ultrarunning subreddit\n",
      "Scraped 200 posts for the ultrarunning subreddit\n",
      "Scraped 300 posts for the ultrarunning subreddit\n",
      "Scraped 400 posts for the ultrarunning subreddit\n",
      "Scraped 500 posts for the ultrarunning subreddit\n",
      "Scraped 600 posts for the ultrarunning subreddit\n",
      "Scraped 700 posts for the ultrarunning subreddit\n",
      "Scraped 800 posts for the ultrarunning subreddit\n",
      "Scraped 900 posts for the ultrarunning subreddit\n",
      "Scraped 1000 posts for the ultrarunning subreddit\n",
      "Scraped 1100 posts for the ultrarunning subreddit\n",
      "Scraped 1200 posts for the ultrarunning subreddit\n",
      "Scraped 1300 posts for the ultrarunning subreddit\n",
      "Scraped 1400 posts for the ultrarunning subreddit\n",
      "Scraped 1500 posts for the ultrarunning subreddit\n",
      "Scraped 1600 posts for the ultrarunning subreddit\n",
      "Scraped 1700 posts for the ultrarunning subreddit\n",
      "Scraped 1800 posts for the ultrarunning subreddit\n",
      "Scraped 1900 posts for the ultrarunning subreddit\n",
      "Scraped 2000 posts for the ultrarunning subreddit\n"
     ]
    }
   ],
   "source": [
    "# This scraper is at the mercy of the pushshift API, which at the time of submitting this project, was down and providing a 521 error\n",
    "\n",
    "base_url = 'https://api.pushshift.io/reddit'\n",
    "dfs = []\n",
    "subreddits = ['backpacking', 'ultrarunning']\n",
    "for subreddit in subreddits:\n",
    "    before = int(time.time()) # now\n",
    "    for i in range(1, 21): ]\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 100,\n",
    "            'before': before\n",
    "        }\n",
    "        res = requests.get(base_url + '/search/submission/?', params=params)\n",
    "        if res.status_code == 200:\n",
    "            df = res.json()\n",
    "            posts = pd.DataFrame(df['data'])[['title', 'selftext', 'subreddit', 'created_utc']]\n",
    "            dfs.append(posts)\n",
    "        print(f'Scraped {i * 100} posts for the {subreddit} subreddit')\n",
    "        before = posts['created_utc'].values[-1]\n",
    "        time.sleep(3)\n",
    "        \n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988d9e0f-bbd2-4fd7-8546-5ff2362b77ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backpacking     2000\n",
       "ultrarunning    2000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f87db5f-e6c1-45fa-9d4d-a9427bae1fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Eye Catching Kite - Let's Your Friends To Pi...</td>\n",
       "      <td></td>\n",
       "      <td>backpacking</td>\n",
       "      <td>1650589760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backpacking Europe for 6 weeks - thoughts or s...</td>\n",
       "      <td>Hello fellow backpackers - 4 of us (M 22) are ...</td>\n",
       "      <td>backpacking</td>\n",
       "      <td>1650579534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best tour company for hiking to Machu Picchu</td>\n",
       "      <td>Im looking to go to Peru in about a month and ...</td>\n",
       "      <td>backpacking</td>\n",
       "      <td>1650579379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shop Day’s Tactical Gear for all your men’s an...</td>\n",
       "      <td></td>\n",
       "      <td>backpacking</td>\n",
       "      <td>1650572875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nepal Trip</td>\n",
       "      <td>Planning a 1 month trip to Nepal later this ye...</td>\n",
       "      <td>backpacking</td>\n",
       "      <td>1650569750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A Eye Catching Kite - Let's Your Friends To Pi...   \n",
       "1  Backpacking Europe for 6 weeks - thoughts or s...   \n",
       "2       Best tour company for hiking to Machu Picchu   \n",
       "3  Shop Day’s Tactical Gear for all your men’s an...   \n",
       "4                                         Nepal Trip   \n",
       "\n",
       "                                            selftext    subreddit  created_utc  \n",
       "0                                                     backpacking   1650589760  \n",
       "1  Hello fellow backpackers - 4 of us (M 22) are ...  backpacking   1650579534  \n",
       "2  Im looking to go to Peru in about a month and ...  backpacking   1650579379  \n",
       "3                                                     backpacking   1650572875  \n",
       "4  Planning a 1 month trip to Nepal later this ye...  backpacking   1650569750  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dce7456-296a-4f81-8e7d-8e17a6c5bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to CSV\n",
    "df.to_csv('../raw_data/reddit.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
